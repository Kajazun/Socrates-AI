# -*- coding: utf-8 -*-
"""Socrates.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lKEFXEl3bYyDxK79dpTLnT3lhxNa574n
"""

import gradio as gr
from groq import Groq
import PyPDF2
import os

api_key = os.environ.get("GROQ_API_KEY")
client = Groq(api_key=api_key)

WELCOME_MESSAGE = "üèõÔ∏è **Socrates AI:** ’à’≤’ª’∏÷Ç’ú’µ’∂: ’Ü’•÷Ä’¢’•’º’∂’•÷Ñ PDF ’∂’µ’∏÷Ç’©’®, ÷á ’•’Ω ’Ø÷Ö’£’∂’•’¥ ’±’•’¶ ’µ’∏÷Ç÷Ä’°÷Å’∂’•’¨ ’°’µ’∂ ’ç’∏’Ø÷Ä’°’ø’•’Ω’µ’°’∂ ’¥’•’©’∏’§’´ ’¥’´’ª’∏÷Å’∏’æ:"

# 2. CSS & JavaScript Logic
custom_css = """
#socratic-chatbot { transition: all 0.5s ease; border-radius: 15px; border: 2px solid #ddd; }
.help-btn { background-color: #f39c12 !important; color: white !important; font-weight: bold; }
.flashcard { background: white; border-left: 6px solid #2d5a88; padding: 12px; margin: 8px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }
#mermaid-graph-container { height: 250px; border: 1px solid #ddd; overflow: auto; background: white; border-radius: 8px; padding: 10px; }
"""

combined_js = """
async (history, score, status) => {
    const chatbot = document.querySelector('#socratic-chatbot');
    if (chatbot && status) {
        if (status.includes("üö®")) {
            chatbot.style.backgroundColor = "#ffebeb";
            chatbot.style.borderColor = "#ff7675";
        } else {
            chatbot.style.backgroundColor = "#f0fff4";
            chatbot.style.borderColor = "#55efc4";
        }
    }

    if (history && history.length > 0) {
        const lastMsg = history[history.length - 1][1];
        if (lastMsg && lastMsg.includes("[MAP:")) {
            const concept = lastMsg.match(/\\[MAP:\\s*(.*?)\\]/)[1].replace(/[^a-zA-Z0-9‘±-÷Ü]/g, '_');
            if (!window.logicNodes) window.logicNodes = ["’Ñ’•’Ø’∂’°÷Ä’Ø"];
            if (!window.logicNodes.includes(concept)) {
                window.logicNodes.push(concept);
                let graphDef = "graph LR\\n";
                for (let i = 0; i < window.logicNodes.length - 1; i++) {
                    graphDef += `  ${window.logicNodes[i]} --> ${window.logicNodes[i+1]}\\n`;
                }
                const chartDiv = document.getElementById('mermaid-graph');
                const m = await import('https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs');
                m.default.initialize({ startOnLoad: false, theme: 'forest' });
                const { svg } = await m.default.render('mermaid-' + Date.now(), graphDef);
                chartDiv.innerHTML = svg;
            }
        }
    }
    return [history, score, status];
}
"""

# 3. Functions
def safe_extract_pdf(file):
    if not file: return ""
    try:
        text = ""
        reader = PyPDF2.PdfReader(file.name)
        for page in reader.pages:
            text += page.extract_text() or ""
        return text[:4000]
    except: return "üö® ’ç’≠’°’¨ PDF ÷Ü’°’µ’¨’® ’Ø’°÷Ä’§’°’¨’´’Ω:"

def socratic_chat(user_message, history, model, score, pdf_content, is_help=False):
    if not pdf_content: return history, score, "üö® PDF-’® ’¢’•’º’∂’æ’°’Æ ’π’ß"

    actual_msg = user_message if user_message else "‘≤’°÷Ä÷á, ’Ω’Ø’Ω’•’∂÷Ñ ’∏÷Ç’Ω’∏÷Ç’¥’∂’°’Ω’´÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’®:"

    system_prompt = f"""
    ROLE: Strict Socrates. CONTEXT: {pdf_content[:2500]}.
    STRICT RULES:
    1. ARMENIAN ONLY.
    2. TRUTH CHECK: Compare student's message with PDF context. If they are wrong, you MUST start with [ALERT].
    3. If there is an [ALERT], explain the contradiction briefly but do not give the answer.
    4. Ask only ONE probing question at a time.
    5. End every message with [MAP: CurrentConceptName].
    """

    messages = [{"role": "system", "content": system_prompt}]
    for u, a in history[-3:]:
        if u: messages.append({"role": "user", "content": u})
        if a: messages.append({"role": "assistant", "content": a.replace("‚ö†Ô∏è *’Ä’°’Ø’°’Ω’∏÷Ç’©’µ’∏÷Ç’∂:* ", "[ALERT]")})
    messages.append({"role": "user", "content": actual_msg})

    try:
        res = client.chat.completions.create(model=model, messages=messages, temperature=0.1)
        raw = res.choices[0].message.content.strip()

        is_alert = "[ALERT]" in raw
        status = "üö® ’Ä‘±‘ø‘±’ç’à’í‘π’Ö’à’í’Ü" if is_alert else "‚úÖ ’Ñ’´’ø÷Ñ’® ’∞’Ω’ø’°’Ø ’ß"
        clean = raw.replace("[ALERT]", "‚ö†Ô∏è *’Ä’°’Ø’°’Ω’∏÷Ç’©’µ’∏÷Ç’∂:* ")

        if user_message is None: history = [[None, clean]]
        else: history.append((user_message, clean))

        new_score = score if is_alert else min(100, score + 10)
        return history, new_score, status
    except Exception as e:
        return history, score, f"üö® API ’Ω’≠’°’¨: {str(e)}"

def handle_summary(history, pdf_content):
    if len(history) < 2:
        return "‚ö†Ô∏è ’é’•÷Ä’¨’∏÷Ç’Æ’∏÷Ç’©’µ’°’∂ ’∞’°’¥’°÷Ä ’°’∂’∞÷Ä’°’™’•’∑’ø ’ß ’°’æ’•’¨’´ ’•÷Ä’Ø’°÷Ä ’•÷Ä’Ø’≠’∏’Ω’∏÷Ç’©’µ’∏÷Ç’∂:"

    prompt = f"Analyze this Socratic dialogue based on PDF: {pdf_content[:500]}. History: {str(history)}. Provide strengths, weaknesses and a final grade in Armenian."

    try:
        res = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return res.choices[0].message.content
    except:
        return "üö® ’é’•÷Ä’¨’∏÷Ç’Æ’∏÷Ç’©’µ’∏÷Ç’∂’® ’±’°’≠’∏’≤’æ’•÷Å:"

def generate_flashcards(history, pdf_content):
    source = f"Context: {pdf_content[:500]} History: {str(history[-2:])}"
    try:
        res = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": "Create 3 brief Armenian flashcards. Format: Q|A||Q|A. No intro."},
                {"role": "user", "content": source}
            ],
            temperature=0.1,
            max_tokens=150,
        )
        content = res.choices[0].message.content
        cards = content.split("||")
        html_cards = []
        for c in cards:
            if "|" in c:
                parts = c.split("|")
                html_cards.append(f"<div class='flashcard'><b>‚ùì {parts[0].strip()}</b><hr><i>üí° {parts[1].strip()}</i></div>")
        return "".join(html_cards)
    except:
        return "üö® ’î’°÷Ä’ø’•÷Ä’´ ’£’•’∂’•÷Ä’°÷Å’∏÷Ç’¥’® ’±’°’≠’∏’≤’æ’•÷Å:"

# 4. UI Layout
with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    pdf_storage = gr.State("")

    gr.Markdown("# üèõÔ∏è Socrates: AI-Powered Learning Engine")

    with gr.Row():
        with gr.Column(scale=1):
            pdf_in = gr.File(label="üìÑ ‘≤’•’º’∂’•’¨ PDF ’∂’µ’∏÷Ç’©’®", file_types=[".pdf"])
            model_dd = gr.Dropdown(
                choices=["llama-3.3-70b-versatile", "llama-3.1-8b-instant"],
                value="llama-3.3-70b-versatile",
                label="ü§ñ ‘∏’∂’ø÷Ä’•’¨ AI ’Ñ’∏’§’•’¨’®"
            )
            prog = gr.Slider(label="üéì ’Ö’∏÷Ç÷Ä’°÷Å’¥’°’∂ ’¥’°’Ø’°÷Ä’§’°’Ø", value=0)
            status_box = gr.Textbox(label="‘ø’°÷Ä’£’°’æ’´’≥’°’Ø", interactive=False)

            with gr.Tabs():
                with gr.TabItem("üó∫Ô∏è ’è÷Ä’°’¥’°’¢’°’∂’°’Ø’°’∂ ÷Ñ’°÷Ä’ø’•’¶"):
                    gr.HTML("<div id='mermaid-graph-container'><div id='mermaid-graph'></div></div>")
                with gr.TabItem("üÉè ’à÷Ç’Ω’∏÷Ç’¥’∂’°’Ø’°’∂ ÷Ñ’°÷Ä’ø’•÷Ä"):
                    f_btn = gr.Button("‚ú® ’ç’ø’•’≤’Æ’•’¨ ÷Ñ’°÷Ä’ø’•÷Ä")
                    f_out = gr.HTML()
                with gr.TabItem("üìù ‘±’¥÷É’∏÷É’∏÷Ç’¥"):
                    s_btn = gr.Button("’é’•÷Ä’¨’∏÷Ç’Æ’•’¨ ’°’º’°’ª’®’∂’©’°÷Å’®")
                    s_out = gr.Markdown()

        with gr.Column(scale=2):
            chat = gr.Chatbot(height=500, value=[[None, WELCOME_MESSAGE]], elem_id="socratic-chatbot")
            msg = gr.Textbox(label="’Å’•÷Ä ’∫’°’ø’°’Ω’≠’°’∂’® (Enter)", placeholder="‘≥÷Ä’•÷Ñ ’°’µ’Ω’ø’•’≤...")
            help_btn = gr.Button("üí° ’Ä’∏÷Ç’∑’∏÷Ç’¥", elem_classes="help-btn")

            # Actions
            msg.submit(lambda x, y: ("", y + [[x, None]]), [msg, chat], [msg, chat]).then(
                socratic_chat, [msg, chat, model_dd, prog, pdf_storage], [chat, prog, status_box]
            ).then(None, [chat, prog, status_box], None, js=combined_js)

            help_btn.click(lambda y: y + [[None, None]], [chat], [chat]).then(
                lambda h, m, s, p: socratic_chat("", h, m, s, p, is_help=True), [chat, model_dd, prog, pdf_storage], [chat, prog, status_box]
            ).then(None, [chat, prog, status_box], None, js=combined_js)

            pdf_in.change(lambda f: safe_extract_pdf(f), [pdf_in], [pdf_storage]).then(
                lambda p, m, h, s: socratic_chat(None, h, m, s, p), [pdf_storage, model_dd, chat, prog], [chat, prog, status_box]
            ).then(None, [chat, prog, status_box], None, js=combined_js)

            f_btn.click(generate_flashcards, [chat, pdf_storage], f_out)
            s_btn.click(handle_summary, [chat, pdf_storage], s_out)

if __name__ == "__main__":
    demo.launch()